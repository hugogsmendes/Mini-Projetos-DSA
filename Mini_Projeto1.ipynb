{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNg+0oafpNzqjTOZ0QJeogl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugogsmendes/Mini-Projetos-DSA/blob/main/Mini_Projeto1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini-Projeto 7**\n",
        "\n",
        "## Deep Learning com PyTorch para Classificação de Imagens"
      ],
      "metadata": {
        "id": "Kpq_3lRKYdhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Instalação e Importação dos Pacotes\n",
        "\n",
        "https://pytorch.org"
      ],
      "metadata": {
        "id": "WYBJPbejagP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark"
      ],
      "metadata": {
        "id": "RHvxYxRCwwbZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "gC54Rca3w0DB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -a \"Hugo Mendes\" --iversions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwRTL8LxZFj",
        "outputId": "8e0b87dd-cf7f-481e-bca6-df2df6db246c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Hugo Mendes\n",
            "\n",
            "PIL         : 11.3.0\n",
            "matplotlib  : 3.10.0\n",
            "numpy       : 2.0.2\n",
            "torch       : 2.9.0+cu126\n",
            "torchsummary: 1.5.1\n",
            "torchvision : 0.24.0+cu126\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definindo o Dispositivo para Treinamento do Modelo de IA"
      ],
      "metadata": {
        "id": "eS6KTkCSyEb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco para seleção de dispositivos (CUDA, MPS ou CPU)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  # Prioridade 1: GPU NVIDIA (CUDA)\n",
        "  device = torch.device('cuda')\n",
        "  print('Dispositivo selecionado: GPU NVIDIA (CUDA)')\n",
        "\n",
        "elif torch.backends.mps.is_available():\n",
        "  # Prioridade 2: GPU APPLE (MPS)\n",
        "  device = torch.device('mps')\n",
        "  print('Dispositivo selecionado: GPU Apple (MPS)')\n",
        "\n",
        "else:\n",
        "  # Prioridade 3: CPU\n",
        "  device = torch.device('cpu')\n",
        "  print('Dispositivo selecionado: CPU')\n",
        "\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAUI0-erzSYA",
        "outputId": "31ced2ca-c163-4466-ec90-cabd04ab9ccd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo selecionado: GPU NVIDIA (CUDA)\n",
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Definindo Hiperparâmetros para Treinamento do Modelo de IA"
      ],
      "metadata": {
        "id": "LoqupnzoV1Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**num_epochs = 10** (Número de épocas)\n",
        "\n",
        "*   Uma \"época\" representa uma passagem completa do algoritmo por todo o conjunto de dados de treinamento\n",
        "*   O modelo \"verá e aprenderá com cada exemplo de treinamento um total de 10 vezes\n",
        "\n",
        "**batch_size = 64** (Tamanho do lote)\n",
        "*   Em vez de mostrar ao modelo o conjunto de dados inteiro de uma só vez, nós dividimos em pequenos \"lotes\"\n",
        "*   O modelo processará 64 exemplos de treinamento, calculará o erro médio desse lote e, em seguida, atualizará seus parâmetros (pesos) uma única vez. O processo de repete com os próximos 64 exemplos, e assim por diante, até que todos os dados da época tenham sido vistos\n",
        "\n",
        "**learning_rate = 0.001** (Taxa de aprendizado)\n",
        "*   Ele controla o \"tamanho do passo\" que o modelo dá ao ajustar seus pesos durante o treinamento\n",
        "*   Após cada lote, o modelo calcula a direção para corrigir seus erros (o \"gradiente\"). Em vez de fazer uma correção drástica, ele fará uma correção pequena (multiplicada por 0.001) nessa direção"
      ],
      "metadata": {
        "id": "7CMLWvpFR7OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros do modelo\n",
        "num_epochs = 10 # Número de épocas para treinar\n",
        "batch_size = 64 # Tamanho do lote (batch)\n",
        "learning_rate = 0.001 # Taxa de aprendizado"
      ],
      "metadata": {
        "id": "9tCAfViv0IcN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Carregando os Dados (Imagens) e Definindo as Transformações, DataLoaders e Classes"
      ],
      "metadata": {
        "id": "n8wsbFL6WJwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   transforms.ToTensor(): Converte a imagem (que tem valores de pixel de 0 a 255) em um Tensor do PyTorch e, o mais importante, ajusta a escala desses valores para um intervalo de [0.0, 1.0]\n",
        "*   transforms.Normalize(): Pega esses valores [0.0, 1.0] e os centraliza, mudando o intervalo para [-1.0, 1.0]"
      ],
      "metadata": {
        "id": "dGU2F0KsYZxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as transformações para os dados\n",
        "dsa_transformacoes = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "ibcYDxEmWVIJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e carregar o dataset de treino\n",
        "dsa_dataset_treino = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                  train=True,\n",
        "                                                  download=True,\n",
        "                                                  transform=dsa_transformacoes)"
      ],
      "metadata": {
        "id": "Pbf5ESeLZCZY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e carregar o dataset de teste\n",
        "dsa_dataset_teste = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                 train=False,\n",
        "                                                 download=True,\n",
        "                                                 transform=dsa_transformacoes)"
      ],
      "metadata": {
        "id": "OHUvk_IkZkql"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisamos dos DataLoaders para automatizar e otimizar a entrega dos dados ao modelo durante o treinamento e teste. Eles resolvem três problemas principais:\n",
        "\n",
        "*   **Gerenciamento de memória (Lotes)**: Seu dataset (dsa_dataset_treino) pode ter 100.000 imagens. Elas não cabem todas na memória de uma só vez. O DataLoader pega esse dataset e o serve em \"lotes\" pequenos (batch_size = 64), um de cada vez\n",
        "*   **Embaralhamento (Evitar Vício)**: shuffle=True (para treino) a cada época, ele embaralha os dados de treino. shuffle=False (para teste) garante que os dados de teste sejam avaliados na mesma ordem\n",
        "*   **Eficiência (Paralelismo)**: O DataLoader pode usar múltiplos \"trabalhadores\" (processos) para carregar os próximos lotes de dados enquanto a GPU ainda está processando o lote atual, evitando gargalos e acelerando o treinamento"
      ],
      "metadata": {
        "id": "Vnhk0lN2aklM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar os DataLoaders para carregar os dados em lotes\n",
        "dsa_loader_treino = torch.utils.data.DataLoader(dsa_dataset_treino,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = True)\n",
        "\n",
        "dsa_loader_teste = torch.utils.data.DataLoader(dsa_dataset_teste,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = False)"
      ],
      "metadata": {
        "id": "xwaNY4F5cotl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as classes do CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "OaYHkW54dMaT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Número de imagens de treino: {len(dsa_dataset_treino)}')\n",
        "print(f'Número de imagens de teste: {len(dsa_dataset_teste)}')\n",
        "print(f'Número de lotes (batches) de treino: {len(dsa_loader_treino)}')\n",
        "print(f'Número de lotes (batches) de teste: {len(dsa_loader_teste)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXtuuL01dVUG",
        "outputId": "b9ac1fd6-00fd-4864-d42b-296bd630d7d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de imagens de treino: 50000\n",
            "Número de imagens de teste: 10000\n",
            "Número de lotes (batches) de treino: 782\n",
            "Número de lotes (batches) de teste: 157\n"
          ]
        }
      ]
    }
  ]
}