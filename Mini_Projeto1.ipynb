{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyYuZViMfupTWyETKWbHSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugogsmendes/Mini-Projetos-DSA/blob/main/Mini_Projeto1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini-Projeto 1**\n",
        "\n",
        "## Deep Learning com PyTorch para Classificação de Imagens"
      ],
      "metadata": {
        "id": "Kpq_3lRKYdhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Instalação e Importação dos Pacotes\n",
        "\n",
        "https://pytorch.org"
      ],
      "metadata": {
        "id": "WYBJPbejagP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U watermark"
      ],
      "metadata": {
        "id": "RHvxYxRCwwbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24259c88-33d2-4eab-b317-4fb9439ad7d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "gC54Rca3w0DB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -a \"Hugo Mendes\" --iversions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwRTL8LxZFj",
        "outputId": "38f32f7c-80bb-46af-b111-7928c142956b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Hugo Mendes\n",
            "\n",
            "PIL         : 11.3.0\n",
            "matplotlib  : 3.10.0\n",
            "numpy       : 2.0.2\n",
            "torch       : 2.9.0+cu126\n",
            "torchsummary: 1.5.1\n",
            "torchvision : 0.24.0+cu126\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definindo o Dispositivo para Treinamento do Modelo de IA"
      ],
      "metadata": {
        "id": "eS6KTkCSyEb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco para seleção de dispositivos (CUDA, MPS ou CPU)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  # Prioridade 1: GPU NVIDIA (CUDA)\n",
        "  device = torch.device('cuda')\n",
        "  print('Dispositivo selecionado: GPU NVIDIA (CUDA)')\n",
        "\n",
        "elif torch.backends.mps.is_available():\n",
        "  # Prioridade 2: GPU APPLE (MPS)\n",
        "  device = torch.device('mps')\n",
        "  print('Dispositivo selecionado: GPU Apple (MPS)')\n",
        "\n",
        "else:\n",
        "  # Prioridade 3: CPU\n",
        "  device = torch.device('cpu')\n",
        "  print('Dispositivo selecionado: CPU')\n",
        "\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAUI0-erzSYA",
        "outputId": "7567e1ac-bb87-49c5-9f0e-f7f27628c8dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo selecionado: GPU NVIDIA (CUDA)\n",
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Definindo Hiperparâmetros para Treinamento do Modelo de IA"
      ],
      "metadata": {
        "id": "LoqupnzoV1Rm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**num_epochs = 10** (Número de épocas)\n",
        "\n",
        "*   Uma \"época\" representa uma passagem completa do algoritmo por todo o conjunto de dados de treinamento\n",
        "*   O modelo \"verá e aprenderá com cada exemplo de treinamento um total de 10 vezes\n",
        "\n",
        "**batch_size = 64** (Tamanho do lote)\n",
        "*   Em vez de mostrar ao modelo o conjunto de dados inteiro de uma só vez, nós dividimos em pequenos \"lotes\"\n",
        "*   O modelo processará 64 exemplos de treinamento, calculará o erro médio desse lote e, em seguida, atualizará seus parâmetros (pesos) uma única vez. O processo de repete com os próximos 64 exemplos, e assim por diante, até que todos os dados da época tenham sido vistos\n",
        "\n",
        "**learning_rate = 0.001** (Taxa de aprendizado)\n",
        "*   Ele controla o \"tamanho do passo\" que o modelo dá ao ajustar seus pesos durante o treinamento\n",
        "*   Após cada lote, o modelo calcula a direção para corrigir seus erros (o \"gradiente\"). Em vez de fazer uma correção drástica, ele fará uma correção pequena (multiplicada por 0.001) nessa direção"
      ],
      "metadata": {
        "id": "7CMLWvpFR7OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparâmetros do modelo\n",
        "num_epochs = 10 # Número de épocas para treinar\n",
        "batch_size = 64 # Tamanho do lote (batch)\n",
        "learning_rate = 0.001 # Taxa de aprendizado"
      ],
      "metadata": {
        "id": "9tCAfViv0IcN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Carregando os Dados (Imagens) e Definindo as Transformações, DataLoaders e Classes"
      ],
      "metadata": {
        "id": "n8wsbFL6WJwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   transforms.ToTensor(): Converte a imagem (que tem valores de pixel de 0 a 255) em um Tensor do PyTorch e, o mais importante, ajusta a escala desses valores para um intervalo de [0.0, 1.0]\n",
        "*   transforms.Normalize(): Pega esses valores [0.0, 1.0] e os centraliza, mudando o intervalo para [-1.0, 1.0]"
      ],
      "metadata": {
        "id": "dGU2F0KsYZxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as transformações para os dados\n",
        "dsa_transformacoes = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "ibcYDxEmWVIJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e carregar o dataset de treino\n",
        "dsa_dataset_treino = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                  train=True,\n",
        "                                                  download=True,\n",
        "                                                  transform=dsa_transformacoes)"
      ],
      "metadata": {
        "id": "Pbf5ESeLZCZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cec050b-d40d-4935-a8b6-45fdc5767e73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:15<00:00, 10.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e carregar o dataset de teste\n",
        "dsa_dataset_teste = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                 train=False,\n",
        "                                                 download=True,\n",
        "                                                 transform=dsa_transformacoes)"
      ],
      "metadata": {
        "id": "OHUvk_IkZkql"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisamos dos DataLoaders para automatizar e otimizar a entrega dos dados ao modelo durante o treinamento e teste. Eles resolvem três problemas principais:\n",
        "\n",
        "*   **Gerenciamento de memória (Lotes)**: Seu dataset (dsa_dataset_treino) pode ter 100.000 imagens. Elas não cabem todas na memória de uma só vez. O DataLoader pega esse dataset e o serve em \"lotes\" pequenos (batch_size = 64), um de cada vez\n",
        "*   **Embaralhamento (Evitar Vício)**: shuffle=True (para treino) a cada época, ele embaralha os dados de treino. shuffle=False (para teste) garante que os dados de teste sejam avaliados na mesma ordem\n",
        "*   **Eficiência (Paralelismo)**: O DataLoader pode usar múltiplos \"trabalhadores\" (processos) para carregar os próximos lotes de dados enquanto a GPU ainda está processando o lote atual, evitando gargalos e acelerando o treinamento"
      ],
      "metadata": {
        "id": "Vnhk0lN2aklM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar os DataLoaders para carregar os dados em lotes\n",
        "dsa_loader_treino = torch.utils.data.DataLoader(dsa_dataset_treino,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = True)\n",
        "\n",
        "dsa_loader_teste = torch.utils.data.DataLoader(dsa_dataset_teste,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = False)"
      ],
      "metadata": {
        "id": "xwaNY4F5cotl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as classes do CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "OaYHkW54dMaT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Número de imagens de treino: {len(dsa_dataset_treino)}')\n",
        "print(f'Número de imagens de teste: {len(dsa_dataset_teste)}')\n",
        "print(f'Número de lotes (batches) de treino: {len(dsa_loader_treino)}')\n",
        "print(f'Número de lotes (batches) de teste: {len(dsa_loader_teste)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXtuuL01dVUG",
        "outputId": "3746ca91-111f-4762-9c19-5f1670eb0dd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de imagens de treino: 50000\n",
            "Número de imagens de teste: 10000\n",
            "Número de lotes (batches) de treino: 782\n",
            "Número de lotes (batches) de teste: 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Visualização as Imagens Carregadas"
      ],
      "metadata": {
        "id": "KqYyVtfEXPbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para mostrar a imagem\n",
        "def imshow (img):\n",
        "  img = img / 2 + 0.5 # Desnormaliza de  [-1, 1] para [0, 1]\n",
        "  npimg = img.numpy() # Converte a imagem em formato de matriz NumPy\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0))) # Converte de (C, H, W) para (H, W, C) - Canais (C), Altura (H) e Largura (W)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7mpX7V-eXeZL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtém um lote de imagens de treino\n",
        "dataiter = iter(dsa_loader_treino)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "mym650uGYUdl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as primeiras 4 imagens do lote\n",
        "print(\"Amostra de imagens de treino:\")\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "\n",
        "# Imprime os labels correspondentes\n",
        "print('Labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "qWIl6b2YYout",
        "outputId": "2887d1dc-4f3e-42a5-fb0e-b9913c5b2073"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostra de imagens de treino:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  horse ship  dog   cat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Construção do Modelo de IA"
      ],
      "metadata": {
        "id": "3AL3VZ28a8GU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.deeplearningbook.com.br/introducao-as-redes-neurais-convolucionais/\n",
        "\n",
        "De forma resumida, ele é dividido em duas partes:\n",
        "\n",
        "**__init__(self) (A \"Planta\" da Rede):**\n",
        "\n",
        "- Esta função é o \"construtor\" que declara todas as camadas (as \"peças\") que a rede irá usar.\n",
        "\n",
        "- self.conv1 e self.conv2: São camadas convolucionais que atuam como \"extratores de características\", aprendendo a identificar padrões (como bordas, texturas) na imagem.\n",
        "\n",
        "- self.pool: É uma camada de pooling que reduz o tamanho da imagem (de 28x28 para 14x14, e de 10x10 para 5x5), tornando o modelo mais eficiente e focado nas características mais importantes.\n",
        "\n",
        "- self.fc1, fc2, fc3: São camadas lineares (totalmente conectadas) que atuam como o \"cérebro\" de decisão. Elas recebem as características achatadas (16 * 5 * 5 = 400) e as usam para classificar a imagem. A última camada (fc3) tem 10 saídas, uma para cada categoria final (ex: \"gato\", \"cachorro\", \"avião\", etc.).\n",
        "\n",
        "**forward(self, x) (A \"Linha de Montagem\"):**\n",
        "\n",
        "- Esta função define a ordem exata em que os dados (x, a imagem de entrada) passam pelas camadas.\n",
        "\n",
        "- O fluxo é: Convolução 1 -> Ativação ReLU -> Pooling -> Convolução 2 -> Ativação ReLU -> Pooling.\n",
        "\n",
        "- Após extrair as características, os dados são \"achatados\" (flatten) para se tornarem um vetor longo.\n",
        "\n",
        "- Esse vetor passa pelas camadas de decisão (fc1, fc2, fc3) para produzir o resultado final da classificação."
      ],
      "metadata": {
        "id": "KGO_t8nEhZ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe para criar a arquitetura do modelo\n",
        "class ConvNet(nn.Module):\n",
        "\n",
        "  # Método construtor\n",
        "  def __init__ (self):\n",
        "\n",
        "    # Inicializa o construtor da classe mãe\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    # Input: 3 canais de cor, Output: 6 feature maps, Kernel: 5x5\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "    # Max pooling 2x2\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    # Input: 6 feature maps, Output: 16 feature maps, Kernel: 5x5\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "    # As imagens CIFAR-10 são 32x32\n",
        "    # Após conv1 (5x5): 32-5+1 = 28 -> 28x28\n",
        "    # Após pool1 (2x2): 28/2 = 14 -> 14x14\n",
        "    # Após conv2 (5x5): 14-5+1 = 10 -> 10x10\n",
        "    # Após pool2 (2x2): 10/2 = 5 -> 5x5\n",
        "    # Tamanho achatado (flattened): 16 canais * 5 * 5 = 400 atributos\n",
        "\n",
        "    # Camadas totalmente conectadas (Linear)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120) # 400 -> 120\n",
        "    self.fc2 = nn.Linear(120, 84)         # 120 -> 84\n",
        "    self.fc3 = nn.Linear(84, 10)          # 84 -> 10 (10 classes)\n",
        "\n",
        "    # Método forward (passada para a frente)\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Aplicando as camadas convolucionais e pooling\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "    # Achatar (flatten) o tensor para a camada linear\n",
        "    # Achata todas as dimensões, exceto o batch\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    # Aplicando as camadas lineares com ReLU\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "\n",
        "    # Camada de saída (sem ativação, pois a CrossEntropyLoss aplica Softmax)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "6PrZ34QnZKH5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos instanciar o modelo e movê-lo para a CPU para visualizarmos um resumo do modelo\n",
        "modelo_dsa = ConvNet().to(\"cpu\")"
      ],
      "metadata": {
        "id": "Po5qxpN3jzcS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Arquitetura do Modelo:\")\n",
        "print(modelo_dsa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykstX7hEADfS",
        "outputId": "b0875fb1-b73d-4c10-f6bb-9ae29f19ac04"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitetura do Modelo:\n",
            "ConvNet(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sumário\n",
        "summary(modelo_dsa, (3, 32, 32), device = \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRQCuLxyAHz4",
        "outputId": "1d6929e4-20e6-4624-bf9f-f30c1dbf4f56"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             456\n",
            "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
            "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
            "            Linear-5                  [-1, 120]          48,120\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora instanciamos o modelo e movemos para o dispositivo de treino (GPU)\n",
        "modelo_dsa = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "tiD-mBypAqdD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYgTEmHGCAmA",
        "outputId": "6e689c1a-a15b-4095-aad6-d750c58b83ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Definindo a Função de Perda e Otimizador (Backpropagation)"
      ],
      "metadata": {
        "id": "5frtHtqrCRjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é a função de perda (ou \"critério\"). Ela atua como uma \"régua\" que mede o quão distante as previsões do seu modelo estão das respostas corretas.\n",
        "\n",
        "Em problemas de classificação (como \"gato\" vs \"cachorro\" vs \"avião\"), CrossEntropyLoss é a métrica padrão. Durante o treinamento, ela calcula um único número (a \"perda\") que indica o tamanho do erro. O objetivo de todo o treinamento é minimizar esse número."
      ],
      "metadata": {
        "id": "QLN_Alq6Dvz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a função de perda. O modelo vai buscar os parâmetros que reduzem o erro geral das previsões\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "fmJHhdTmCbRD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este é o otimizador. Se a função de perda é a \"régua\" que mede o erro, o otimizador é o \"mecânico\" que corrige o erro.\n",
        "\n",
        "O otimizador \"olha\" para o erro (calculado pela criterion) e decide exatamente como ajustar cada parâmetro (peso) dentro do modelo_dsa.parameters() para reduzir esse erro no próximo passo.\n",
        "\n",
        "Adam é um algoritmo de otimização moderno e muito popular porque é eficiente e se ajusta automaticamente (adaptativo), funcionando bem na maioria dos casos sem exigir muito ajuste manual. O lr = learning_rate apenas diz a ele o quão \"agressivo\" deve ser esse ajuste."
      ],
      "metadata": {
        "id": "s2gjNA_qECse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Otimizador Adam\n",
        "optimizer = optim.Adam(modelo_dsa.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "q-spIs2EENjL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Treinamento do Modelo"
      ],
      "metadata": {
        "id": "J00W8Ne5Fitg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A célula abaixo é o \"coração\" do processo de treinamento e validação do seu modelo de IA. De forma resumida, ele faz o seguinte:\n",
        "\n",
        "Loop Principal de Épocas (for epoch...): Este é o loop externo. Ele faz o modelo \"estudar\" o conjunto de dados de treinamento inteiro várias vezes (o número de vezes é definido por num_epochs).\n",
        "<!-- Trabalho Desenvolvido no Curso da Data Science Academy - www.datascienceacademy.com.br -->\n",
        "Dentro de cada \"Época\", existem duas fases:\n",
        "\n",
        "**1. Fase de Treinamento (modelo_dsa.train())**\n",
        "\n",
        "Nesta fase, o modelo aprende com os dados:\n",
        "\n",
        "- for i, (images, labels)...: Pega os dados de treino em pequenos lotes (ex: 64 imagens de cada vez).\n",
        "\n",
        "- images.to(device): Move os dados para a GPU para processamento rápido.\n",
        "\n",
        "- outputs = modelo_dsa(images): (Forward) Faz as previsões do modelo para o lote de imagens.\n",
        "\n",
        "- loss = criterion(...): Calcula o \"erro\" (quão ruins foram as previsões) comparando outputs com os rótulos corretos (labels).\n",
        "\n",
        "- optimizer.zero_grad(): Limpa os cálculos de erro da etapa anterior.\n",
        "\n",
        "- loss.backward(): (Backward) Calcula \"para trás\" como cada peso do modelo contribuiu para esse erro (calcula os gradientes).\n",
        "\n",
        "- optimizer.step(): Usa o otimizador (Adam) para ajustar todos os pesos do modelo e reduzir o erro.\n",
        "\n",
        "**2. Fase de Avaliação (modelo_dsa.eval())**\n",
        "\n",
        "Após estudar os dados de treino uma vez, o modelo \"faz uma prova\" para ver o que aprendeu:\n",
        "\n",
        "- modelo_dsa.eval(): Coloca o modelo em modo de avaliação (desliga recursos como dropout).\n",
        "\n",
        "- with torch.no_grad(): Desativa o cálculo de gradientes (pois não vamos treinar), o que economiza muita memória e acelera o processo.\n",
        "\n",
        "- for val_images, val_labels...: Pega os dados do conjunto de teste (dados que o modelo nunca viu no treino).\n",
        "\n",
        "- val_outputs = modelo_dsa(val_images): Faz previsões sobre os dados de teste.\n",
        "\n",
        "- n_correct += ...: Compara as previsões do modelo com as respostas corretas e conta o número total de acertos.\n",
        "\n",
        "**3. Relatório de Progresso**\n",
        "\n",
        "- print(f'Epoch ...'): No final de cada época, ele imprime um resumo: o erro médio do treinamento e a acurácia (percentual de acertos) no teste, permitindo que você veja o modelo melhorar ao longo do tempo."
      ],
      "metadata": {
        "id": "rm1fD_oJGBFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"\\nIniciando o treinamento...\\n\")\n",
        "\n",
        "# Calcula o total de passos por época (número de batches)\n",
        "n_total_steps = len(dsa_loader_treino)\n",
        "\n",
        "# Loop principal de treinamento\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Coloca o modelo em modo de treinamento\n",
        "    modelo_dsa.train()\n",
        "\n",
        "    # Inicializa o acumulador de perda\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Itera sobre os batches do conjunto de treino\n",
        "    for i, (images, labels) in enumerate(dsa_loader_treino):\n",
        "\n",
        "        # Move os tensores (imagens e rótulos) para o dispositivo (CPU ou GPU), próximos do modelo\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Passagem para frente (forward)\n",
        "        # Aqui ocorre a previsão do modelo\n",
        "        outputs = modelo_dsa(images)\n",
        "\n",
        "        # Calcula o erro do modelo\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Zera os gradientes acumulados de iterações anteriores\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calcula os gradientes via backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Atualiza os pesos do modelo\n",
        "        optimizer.step()\n",
        "\n",
        "        # Soma o valor da perda para cálculo médio posterior\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Após cada época, avalia o modelo no conjunto de teste (validação)\n",
        "    # Coloca o modelo em modo de avaliação\n",
        "    modelo_dsa.eval()\n",
        "\n",
        "    # Desativa o cálculo de gradientes para economizar memória e tempo\n",
        "    with torch.no_grad():\n",
        "\n",
        "        n_correct = 0   # Contador de acertos\n",
        "        n_samples = 0   # Contador de amostras\n",
        "\n",
        "        # Loop sobre o conjunto de teste\n",
        "        for val_images, val_labels in dsa_loader_teste:\n",
        "\n",
        "            # Move imagens e rótulos para o dispositivo\n",
        "            val_images = val_images.to(device)\n",
        "            val_labels = val_labels.to(device)\n",
        "\n",
        "            # Faz a inferência no conjunto de teste\n",
        "            val_outputs = modelo_dsa(val_images)\n",
        "\n",
        "            # torch.max retorna (valor, índice) → pegamos o índice da classe prevista\n",
        "            _, predicted = torch.max(val_outputs.data, 1)\n",
        "\n",
        "            # Incrementa o total de amostras\n",
        "            n_samples += val_labels.size(0)\n",
        "\n",
        "            # Incrementa o número de acertos\n",
        "            n_correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "    # Calcula a acurácia e a perda média da época\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    avg_loss = running_loss / n_total_steps\n",
        "\n",
        "    # Exibe métricas de desempenho para a época atual\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Erro em Treino: {avg_loss:.4f}, Acurácia em Teste: {acc:.2f} %')\n",
        "\n",
        "# Exibe mensagem final de conclusão\n",
        "print('\\nTreinamento finalizado.\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPCQYC-FlJp",
        "outputId": "594302f0-4378-43aa-bec1-b3560308fab2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento...\n",
            "\n",
            "Epoch [1/10], Erro em Treino: 1.6560, Acurácia em Teste: 46.23 %\n",
            "Epoch [2/10], Erro em Treino: 1.3687, Acurácia em Teste: 53.05 %\n",
            "Epoch [3/10], Erro em Treino: 1.2418, Acurácia em Teste: 57.02 %\n",
            "Epoch [4/10], Erro em Treino: 1.1546, Acurácia em Teste: 58.17 %\n",
            "Epoch [5/10], Erro em Treino: 1.0898, Acurácia em Teste: 59.59 %\n",
            "Epoch [6/10], Erro em Treino: 1.0340, Acurácia em Teste: 60.56 %\n",
            "Epoch [7/10], Erro em Treino: 0.9889, Acurácia em Teste: 61.60 %\n",
            "Epoch [8/10], Erro em Treino: 0.9499, Acurácia em Teste: 62.11 %\n",
            "Epoch [9/10], Erro em Treino: 0.9138, Acurácia em Teste: 62.26 %\n",
            "Epoch [10/10], Erro em Treino: 0.8810, Acurácia em Teste: 63.44 %\n",
            "\n",
            "Treinamento finalizado.\n",
            "\n",
            "CPU times: user 2min 38s, sys: 505 ms, total: 2min 39s\n",
            "Wall time: 2min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bALGT5WwJrKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}